# voice-to-image
#Overview
This project utilizes OpenAI's Whisper and DALL-E-2 models to convert spoken language into images. It uses Streamlit for the user interface and OpenAI API for model interactions.

#Installation
Install the required Python packages:

pip install -r requirements.txt
Set up OpenAI API key:

Sign up for an OpenAI API key at OpenAI.

Set your API key as an environment variable:

export OPENAI_API_KEY="your-api-key"
Usage
Run the Streamlit app:

streamlit run app.py
Open the provided Streamlit link in your web browser.

Click the "Click here to speak" button to record audio.

The recorded audio is then transcribed using the Whisper model.

The transcribed text is used as a prompt for the DALL-E-2 model to generate an image.

The generated image is displayed on the Streamlit app.

File Structure
app.py: Streamlit app script.
requirements.txt: List of required Python packages.
input.wav: Temporary audio file for user input.
generated_image.jpg: Output image generated by the DALL-E-2 model.
Notes
This project assumes Python 3.6 or later.
Make sure to keep your OpenAI API key confidential.


